##  Interpreting parameters of linear models

```{r echo=FALSE}
knit_hooks$set(basefig=function(before, options, envir) {
                   if (before) {
                       par(bty="l",las=1)
                   } else { }
               })
opts_chunk$set(fig.width=6,fig.height=4,fig.align="center",tidy=FALSE)
``` 

* Parameters of a linear model typically characterize *differences* in means; differences per unit of change for continuous predictors, differences between groups (or between group averages) for categorical predictors
* Interactions are **differences between differences**

### Coding for categorical predictors: contrasts

* What do the parameters of a linear model mean?  
* Start with categorical variables, because they're potentially more confusing ("intercept and slope" isn't too hard)
* Default R behaviour: *treatment contrasts*. $\beta_1$ = expected value in baseline group (= first level of the factor variable, by default the first in alphabetical order);
$\beta_i$ = expected difference between group $i$ and the first group.
```{r define_data1,echo=FALSE}
forest <- c(9, 6, 4, 6, 7, 10)
field  <- c(12, 9, 12, 10)
ants <- data.frame(
  place=rep(c("field","forest"),
            c(length(field), length(forest))),
  colonies=c(field,forest)
)
```
For example, if we took the ants example from our permutations and ran a linear model, the results would look like this:
```{r coefmat1}
pr <- function(m) printCoefmat(coef(summary(m)),digits=3,signif.stars=FALSE)
pr(lm1 <- lm(colonies~place,data=ants))
```
(`pr` is just a utility function I made up for printing compact summaries of the estimates from a linear regression: `summary()` would give the same information plus a lot more I'm not interested in right now.)
The `(Intercept)` row refers to $\beta_1$, which is the mean density in the "field" sites ("field" comes before "forest").  The `placeforest` row tells us we are looking at the effect of the `place` variable on the `forest` level, i.e. the difference between the "forest" and "field" sites.  (The only ways we could know that "field" is the baseline site are (1) to remember, or look at `levels(ants$place)` or (2) to notice which level is *missing* from the list of parameter estimates.)

R's behaviour may seem annoyng at first -- it seems like the estimated values of the groups are what we're really interested in -- but it is really designed for testing *differences among groups*. To get the estimates per group
(what SAS calls `LSMEANS`), you could:
* use a regression formula `colonies~place-1`, or equivalently `colonies~place+0`, to suppress the implicit intercept term:
```{r coefmat0,echo=FALSE}
pr(lm0 <- lm(colonies~place-1,data=ants))
```
* Use the `predict` function:
```{r predict,results="hide"}
predict(lm1,newdata=data.frame(place=c("field","forest")),interval="confidence")
```
* Use the `effects` package:
```{r effects,message=FALSE,warning=FALSE,results="hide"}
library("effects")
summary(allEffects(lm1))
```

You can (and should) look at graphical summaries of your results via
```{r fig.keep="none"}
plot(allEffects(lm1))
```
or
```{r message=FALSE,fig.keep="none"}
library("dotwhisker")
dwplot(lm0)
```

When you use the `colonies~place-1` formula, the meanings of the parameters change: $\beta_1$ is the same (mean of "field"), but $\beta_2$ is 'mean of "field"' rather than ("(field)-(forest)").

Things get slightly more interesting/complicated when we have more than two levels of a categorical variable.  I'll look at some data on lizard perching behaviour, from the `brglm` package (and before that from McCullagh and Nelder *Generalized Linear Models* 1989, ultimately from Schoener 1970 *Ecology* **51**:408-418).  I'm going to ignore the fact that these data might best be fitted with generalized linear models.

```{r fakelizards}
data(lizards,package="brglm")
lizards <- transform(lizards,N=grahami+opalinus,
                     gfrac=grahami/(grahami+opalinus))
```

A quick look at the data: response is number of *Anolis grahami* lizards found on perches in particular conditions.
```{r echo=FALSE,message=FALSE,fig.height=4}
require("reshape2")
library("ggplot2")
theme_set(theme_bw()) 
mliz <- melt(lizards,id.vars="grahami",measure.vars=c("height","diameter","light","time"))
ggplot(mliz,aes(x=value,y=grahami))+geom_boxplot(,fill="lightgray")+
  facet_wrap(~variable,scale="free_x",nrow=1)+
  geom_hline(yintercept=mean(lizards$grahami),colour="red",lwd=1,alpha=0.4)
```

For a moment we're going to just look at the `time` variable.
If we leave the factors as is (alphabetical) then $\beta_1$="early", $\beta_2$="late"-"early", $\beta_3$="midday"-"early".  At the very least, it probably makes sense to change the order of the levels:
```{r reordertime}
lizards$time <- factor(lizards$time,levels=c("early","midday","late"))
```
All this does (since we haven't changed the baseline factor) is swap the definitions of $\beta_2$ and $\beta_3$.

In a linear model, we could also use so-called *sum-to-zero* contrasts:
```{r lizardsum}
pr(lm(grahami~time,data=lizards,contrasts=list(time=contr.sum)))
```
Now the `(Intercept)` parameter is the overall mean: `time1` and `time2` are the deviations of the first ("early") and second ("midday") groups from the overall mean. (The names are useless: the `car` package offers a slightly better alternative called `contr.Sum`).
There are other ways to change the contrasts (i.e., use the `contrasts()` function to change the contrasts for a particular variable permanently, or use `options(contrasts=c("contr.sum","contr.poly")))` to change the contrasts for *all* variables), but the way shown above may be the most transparent.

There are other options for contrasts such as `MASS::contr.sdif()`,
which gives the successive differences between levels.
```{r lizardsdif}
library("MASS")
pr(lm(grahami~time,data=lizards,contrasts=list(time=contr.sdif)))
```
You might have particular contrasts in mind (e.g. "control" vs. all other treatments, then "low" vs "high" within treatments), in which case it is probably worth learning how to set contrasts.  (We will talk about testing *all pairwise differences later*, when we discuss multiple comparisons.  This approach is probably not as useful as it is common.)

## Multiple treatments and interactions

### Additive model

Let's consider the `light` variable in addition to `time`.
```{r lizardTL1}
pr(lmTL1 <- lm(grahami~time+light,data=lizards))
```

Here's a graphical interpretation of the parameters:

```{r lizardcontrasts1,echo=FALSE}
require("grid")
pp <- with(lizards,expand.grid(time=levels(time),light=levels(light)))
pp$grahami <- predict(lmTL1,newdata=pp)
cc <- as.list(plyr::rename(coef(lmTL1),c(`(Intercept)`="int")))
labelpos <- with(cc,
  list(x=c(1,2,3,1),xend=c(1,2,3,1),
      y=c(int,int,int,int),
      yend=c(int,int+timemidday,int+timelate,int+lightsunny)))
xpos <- -0.1
ggplot(pp,aes(x=time,y=grahami,colour=light))+geom_point()+
  geom_line(aes(group=light))+
  annotate("segment",x=labelpos$x,xend=labelpos$xend,y=labelpos$y,
           yend=labelpos$yend,alpha=0.5,
           arrow=arrow(length = unit(0.3,"cm"),ends="both"))+
  annotate("text",x=with(labelpos,(x+xend)/2)+xpos,y=with(labelpos,(y+yend)/2),
label=paste0("beta[",1:4,"]"),parse=TRUE)+
  annotate("segment",x=labelpos$x[1],xend=labelpos$x[3],y=labelpos$y[1],
           yend=labelpos$y[1],alpha=0.3,lty=2)
```
$\beta_1$ is the intercept ("early","sunny"); $\beta_2$ and $\beta_3$ are the differences from the baseline level ("early") of the *first* variable (`time`) in the *baseline* level of the other parameter(s) (`light`="shady"); $\beta_4$ is the difference from the baseline level ("sunny") of the *second* variable (`light`) in the *baseline* level of `time` ("early").

Now let's look at an interaction model:

```{r lizardTL2}
pr(lmTL2 <- lm(grahami~time*light,data=lizards))
```

```{r lizardcontrasts2,echo=FALSE}
gg_color_hue <- function(n) {
  hues = seq(15, 375, length=n+1)
  hcl(h=hues, l=65, c=100)[1:n]
}
pp2 <- pp
pp2$grahami <- predict(lmTL2,newdata=pp)
cc <- as.list(plyr::rename(coef(lmTL2),c(`(Intercept)`="int",
        `timemidday:lightsunny`="midsunny",`timelate:lightsunny`="latesunny")))
labelpos <- with(cc,
  list(x=c(1,2,3,1,2,3),xend=c(1,2,3,1,2,3),
      y=c(int,int,int,int,int+lightsunny+timemidday,int+lightsunny+timelate),
      yend=c(int,int+timemidday,int+timelate,int+lightsunny,
             int+timemidday+lightsunny+midsunny,int+timelate+lightsunny+latesunny)))
xpos <- -0.1
ggplot(pp2,aes(x=time,y=grahami,colour=light))+geom_point()+
  geom_line(aes(group=light))+
  annotate("segment",x=1:2,xend=2:3,
           y=with(cc,c(int+lightsunny,int+timemidday+lightsunny)),
           yend=with(cc,c(int+timemidday+lightsunny,int+timelate+lightsunny)),
           colour=gg_color_hue(2)[2],lty=2)+
  annotate("segment",x=labelpos$x,xend=labelpos$xend,y=labelpos$y,
           yend=labelpos$yend,alpha=0.5) +
           ## arrow=arrow(length = unit(0.3,"cm"),ends="both"))+
  annotate("text",x=with(labelpos,(x+xend)/2)+xpos,y=with(labelpos,(y+yend)/2),
label=paste0("beta[",1:6,"]"),parse=TRUE)+
  annotate("segment",x=rep(labelpos$x[1],2),
                     xend=rep(labelpos$x[3],2),
                     y=labelpos$yend[c(1,4)],
                     yend=labelpos$yend[c(1,4)],alpha=0.3,lty=2)
```
Parameters $\beta_1$ to $\beta_4$ have the same meanings as before.
Now we also have $\beta_5$ and $\beta_6$, labelled "timemidday:lightsunny" and "timelate:lightsunny", which describe the difference between the expected mean value of these treatment combinations based on the additive model (which are $\beta_1 + \beta_2 + \beta_4$ and $\beta_1 + \beta_3 + \beta_4$ respectively) and their actual values.


Now re-do this for sum-to-zero contrasts ... the fits are easy:
```{r lizardTL1S}
pr(lmTL1S <- update(lmTL1,contrasts=list(time=contr.sum,light=contr.sum)))
```

```{r lizardTL2S}
pr(lmTL2S <- update(lmTL2,contrasts=list(time=contr.sum,light=contr.sum)))
```

(The intercept doesn't stay exactly the same when we add the interaction
because the data are unbalanced:
try `with(lizards,table(light,time))`)


The pictures will be a pain -- maybe draw by hand?

Session info:
```{r}
sessionInfo()
```

Other refs
* http://sas-and-r.blogspot.com/2010/10/example-89-contrasts.html
* [`gmodels::fit.contrast()`](http://hosho.ees.hokudai.ac.jp/~kubo/Rdoc/library/gmodels/html/fit.contrast.html) (show parameter estimates based on re-fitting models with new contrasts), [`rms::contrast.rms()`](http://hosho.ees.hokudai.ac.jp/~kubo/Rdoc/library/rms/html/contrast.html) (ditto, for `rms`-based fits)
* http://www.ats.ucla.edu/stat/r/library/contrast_coding.htm
* Crawley *Statistical Computing: An Introduction to Data Analysis
using S-PLUS*, chapter 18
